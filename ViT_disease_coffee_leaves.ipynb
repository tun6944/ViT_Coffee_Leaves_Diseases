{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "L3DhJgSehS-S",
      "metadata": {
        "id": "L3DhJgSehS-S"
      },
      "source": [
        "# Phân loại bệnh lá cà phê (healthy, cercospora, miner, mite, phoma, rust)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "oEU_ucrbhsFC",
      "metadata": {
        "id": "oEU_ucrbhsFC"
      },
      "outputs": [],
      "source": [
        "import os, sys\n",
        "if 'google.colab' in sys.modules:\n",
        "    print(\"Chạy trên Google Colab\")\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    !unzip -o -q /content/drive/MyDrive/dataset.zip -d dataset\n",
        "    DATADIR = 'dataset'\n",
        "    OUTPUT = '/content/drive/MyDrive/output_ViT/'\n",
        "    print(DATADIR)\n",
        "elif os.path.exists('/kaggle'):\n",
        "    print(\"Chạy trên Kaggle\")\n",
        "    DATADIR = '/kaggle/input/coffee-leaf'\n",
        "    OUTPUT = '/kaggle/working/'\n",
        "    print(DATADIR)\n",
        "else:\n",
        "    print(\"Chạy locally\")\n",
        "    DATADIR = 'dataset'\n",
        "    OUTPUT = ''\n",
        "    print(DATADIR)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "DJnU9A1bsesN",
      "metadata": {
        "id": "DJnU9A1bsesN"
      },
      "source": [
        "## 1) Cài đặt và kiểm tra môi trường"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZPo41K1oyOEV",
      "metadata": {
        "id": "ZPo41K1oyOEV"
      },
      "outputs": [],
      "source": [
        "!pip install safetensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hlOYDbkphS-a",
      "metadata": {
        "id": "hlOYDbkphS-a"
      },
      "outputs": [],
      "source": [
        "import random, pathlib, time, math\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "from torchvision import transforms\n",
        "from PIL import Image, ImageFile\n",
        "import shutil\n",
        "import cv2\n",
        "import timm\n",
        "import json\n",
        "from timm.data.mixup import Mixup\n",
        "from timm.loss import SoftTargetCrossEntropy\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from transformers import ViTForImageClassification, ViTConfig\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "from tqdm.auto import tqdm\n",
        "import pickle\n",
        "import datetime\n",
        "import logging\n",
        "from torch.amp import autocast\n",
        "import tensorflow as tf\n",
        "from torch.optim.lr_scheduler import SequentialLR, LinearLR, CosineAnnealingLR\n",
        "logging.getLogger('tensorflow').setLevel(logging.ERROR)\n",
        "tf.get_logger().setLevel('ERROR')\n",
        "\n",
        "print('PyTorch:', torch.__version__)\n",
        "if torch.cuda.is_available():\n",
        "    t = torch.cuda.get_device_properties(0)\n",
        "    print('GPU:', torch.cuda.get_device_name(0))\n",
        "    print(f\"Device count: {torch.cuda.device_count()}\")\n",
        "    print(f\"Current device: {torch.cuda.current_device()}\")\n",
        "    print(f\"Device name: {torch.cuda.get_device_name(torch.cuda.current_device())}\")\n",
        "    print(f\"Total VRAM: {t.total_memory / (1024**3):.2f} GB\")\n",
        "else:\n",
        "    print(' Chạy trên CPU — sẽ chậm hơn.')\n",
        "\n",
        "print(f\"CUDA Available on PC: {torch.cuda.is_available()}\")\n",
        "\n",
        "USE_TORCH_COMPILE = True\n",
        "USE_CHANNELS_LAST = True\n",
        "\n",
        "torch.backends.cudnn.enabled = True\n",
        "torch.backends.cudnn.benchmark = True"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "auEw3laehS-d",
      "metadata": {
        "id": "auEw3laehS-d"
      },
      "source": [
        "## 2) Cấu hình & seed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0szVeby_hS-e",
      "metadata": {
        "id": "0szVeby_hS-e"
      },
      "outputs": [],
      "source": [
        "print(f\"Bắt đầu quá trình lúc: {datetime.datetime.now()}\")\n",
        "SEED = 42\n",
        "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "# Cấu hình\n",
        "DATASET_DIR = Path(DATADIR)\n",
        "if not DATASET_DIR.exists():\n",
        "    alt = Path('processed_dataset')\n",
        "    if alt.exists():\n",
        "        DATASET_DIR = alt\n",
        "        print(f\"Thư mục {DATADIR} không tồn tại, dùng {alt} thay thế.\")\n",
        "    else:\n",
        "        raise FileNotFoundError(f'Không tìm thấy thư mục {DATASET_DIR.resolve()}')\n",
        "\n",
        "MODEL_NAME = 'google/vit-base-patch16-224'\n",
        "if not (('google.colab' in sys.modules) or os.path.exists('/kaggle')):\n",
        "    local_model_dir = Path(__file__).parent / \"vit-base-patch16-224\"\n",
        "    print(local_model_dir)\n",
        "else:\n",
        "    local_model_dir = False\n",
        "    print(local_model_dir)\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 40\n",
        "BASE_LR = 1e-4\n",
        "WEIGHT_DECAY = 0.05\n",
        "WARMUP_EPOCHS = EPOCHS / 10\n",
        "LABEL_SMOOTHING = 0.1\n",
        "MIXUP = True\n",
        "MIXUP_ALPHA = 0.4\n",
        "CUTMIX_ALPHA = 0.0\n",
        "TRAIN_RATIO, VAL_RATIO, TEST_RATIO = 0.8, 0.1, 0.1\n",
        "if ('google.colab' in sys.modules) or os.path.exists('/kaggle'):\n",
        "    NUM_WORKERS = os.cpu_count() // 2\n",
        "else:\n",
        "    NUM_WORKERS = 0\n",
        "\n",
        "PIN_MEMORY = torch.cuda.is_available()\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "USE_PROCESSED = False\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "print('Thiết bị:', DEVICE)\n",
        "print('NUM_WORKERS:', NUM_WORKERS)\n",
        "print('PIN_MEMORY:', PIN_MEMORY)\n",
        "\n",
        "ALLOWED_EXTS = {'.jpg', '.jpeg', '.png'}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bo3JZW90hS-f",
      "metadata": {
        "id": "bo3JZW90hS-f"
      },
      "source": [
        "## 3) Liệt kê dữ liệu & tách train/val/test (stratified theo lớp) + lọc ảnh lỗi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "x-0V9DAFhS-f",
      "metadata": {
        "id": "x-0V9DAFhS-f"
      },
      "outputs": [],
      "source": [
        "\n",
        "processed_dir = Path(OUTPUT + 'processed_dataset')\n",
        "if USE_PROCESSED and (processed_dir.exists() and (processed_dir / 'train').exists()):\n",
        "    print(f\"Tìm thấy thư mục processed_dataset, sẽ dùng split đã có và bỏ qua bước tách/lọc.\")\n",
        "    train_dir = processed_dir / 'train'\n",
        "    val_dir = processed_dir / 'val'\n",
        "    test_dir = processed_dir / 'test'\n",
        "    CLASS_NAMES = sorted([p.name for p in train_dir.iterdir() if p.is_dir()])\n",
        "    NUM_CLASSES = len(CLASS_NAMES)\n",
        "    print('Lớp (processed):', CLASS_NAMES)\n",
        "    print('Số lớp:', NUM_CLASSES)\n",
        "    def list_images_from_dir_existing(directory):\n",
        "        paths, labels = [], []\n",
        "        for idx, cls in enumerate(CLASS_NAMES):\n",
        "            cls_dir = directory / cls\n",
        "            files = [str(p) for p in cls_dir.rglob('*') if p.is_file() and p.suffix.lower() in ALLOWED_EXTS]\n",
        "            paths.extend(files)\n",
        "            labels.extend([idx] * len(files))\n",
        "        return paths, labels\n",
        "    train_paths, train_labels = list_images_from_dir_existing(train_dir)\n",
        "    val_paths, val_labels = list_images_from_dir_existing(val_dir)\n",
        "    test_paths, test_labels = list_images_from_dir_existing(test_dir)\n",
        "    print(f'Train: {len(train_paths)} | Val: {len(val_paths)} | Test: {len(test_paths)}')\n",
        "else:\n",
        "    CLASS_NAMES = sorted([p.name for p in DATASET_DIR.iterdir() if p.is_dir()])\n",
        "    NUM_CLASSES = len(CLASS_NAMES)\n",
        "    print('Lớp:', CLASS_NAMES)\n",
        "    print('Số lớp:', NUM_CLASSES)\n",
        "\n",
        "    output_data_dir = Path(OUTPUT + 'processed_dataset')\n",
        "    train_dir = output_data_dir / 'train'\n",
        "    val_dir = output_data_dir / 'val'\n",
        "    test_dir = output_data_dir / 'test'\n",
        "\n",
        "    def is_valid_image(path):\n",
        "        p = Path(path)\n",
        "        if not p.exists() or p.stat().st_size == 0:\n",
        "            return False\n",
        "        try:\n",
        "            with Image.open(p) as img:\n",
        "                img.verify()\n",
        "            return True\n",
        "        except Exception:\n",
        "            return False\n",
        "\n",
        "    def list_images_by_class(src_dir):\n",
        "        classes = sorted([d.name for d in Path(src_dir).iterdir() if d.is_dir()])\n",
        "        per_class = {}\n",
        "        for cls in tqdm(classes, desc=\"Đang xử lý lớp\"):\n",
        "            cls_dir = Path(src_dir) / cls\n",
        "            files = [str(p) for p in cls_dir.rglob('*') if p.suffix.lower() in ALLOWED_EXTS]\n",
        "            valid_files = [f for f in files if is_valid_image(f)]\n",
        "            per_class[cls] = valid_files\n",
        "            print(f\"{cls}: {len(valid_files)} ảnh hợp lệ\")\n",
        "        return per_class\n",
        "    def stratified_split(per_class, seed=SEED, train_ratio=0.8, val_ratio=0.1, test_ratio=0.1):\n",
        "        rng = np.random.default_rng(seed)\n",
        "        train, val, test = [], [], []\n",
        "        for cls, files in per_class.items():\n",
        "            idx = np.arange(len(files))\n",
        "            rng.shuffle(idx)\n",
        "            files = [files[i] for i in idx]\n",
        "            n = len(files)\n",
        "            n_train = int(n * train_ratio)\n",
        "            n_val = int(n * val_ratio)\n",
        "            train += [(f, cls) for f in files[:n_train]]\n",
        "            val += [(f, cls) for f in files[n_train:n_train+n_val]]\n",
        "            test += [(f, cls) for f in files[n_train+n_val:]]\n",
        "        return train, val, test\n",
        "    def copy_files(pairs, out_dir):\n",
        "        for path, cls in tqdm(pairs, desc=f\"Copy to {out_dir.name}\"):\n",
        "            dst_dir = out_dir / cls\n",
        "            dst_dir.mkdir(parents=True, exist_ok=True)\n",
        "            shutil.copy2(path, dst_dir / Path(path).name)\n",
        "\n",
        "    train_paths, val_paths, test_paths = [], [], []\n",
        "    train_labels, val_labels, test_labels = [], [], []\n",
        "\n",
        "    print(f'\\nTổng train: {len(train_paths)} | val: {len(val_paths)} | test: {len(test_paths)}')\n",
        "\n",
        "    seed=SEED\n",
        "    src = Path(DATADIR)\n",
        "    out = Path(OUTPUT + 'processed_dataset')\n",
        "    out.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    print(\"Đang lọc ảnh hợp lệ...\")\n",
        "    per_class = list_images_by_class(src)\n",
        "\n",
        "    print(\"\\nĐang tách train/val/test...\")\n",
        "    train, val, test = stratified_split(per_class, seed)\n",
        "\n",
        "    print(f\"Tổng train: {len(train)}, val: {len(val)}, test: {len(test)}\")\n",
        "\n",
        "    print(\"\\nĐang sao chép ảnh...\")\n",
        "    copy_files(train, out / 'train')\n",
        "    copy_files(val, out / 'val')\n",
        "    copy_files(test, out / 'test')\n",
        "\n",
        "    print(\"\\nHoàn tất! Dữ liệu đã lưu tại:\", out)\n",
        "    print(f\"Tách và lọc ảnh hoàn tất lúc: {datetime.datetime.now()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dRMGnwgghS-i",
      "metadata": {
        "id": "dRMGnwgghS-i"
      },
      "source": [
        "## 4) Dataset & Transforms (augmentation) + fallback OpenCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5KiDok3qhS-j",
      "metadata": {
        "id": "5KiDok3qhS-j"
      },
      "outputs": [],
      "source": [
        "# Chuẩn hoá theo ImageNet\n",
        "IMAGENET_MEAN = (0.485, 0.456, 0.406)\n",
        "IMAGENET_STD = (0.229, 0.224, 0.225)\n",
        "\n",
        "# RandAugment nếu có, fallback ColorJitter nếu không\n",
        "try:\n",
        "    rand_aug = [transforms.RandAugment(num_ops=2, magnitude=9)]\n",
        "except Exception as e:\n",
        "    print('RandAugment không khả dụng, dùng ColorJitter thay thế.')\n",
        "    rand_aug = [transforms.ColorJitter(0.2,0.2,0.2,0.1)]\n",
        "\n",
        "train_tfms = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(IMG_SIZE, scale=(0.8, 1.0)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    *rand_aug,\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD)\n",
        "])\n",
        "\n",
        "eval_tfms = transforms.Compose([\n",
        "    transforms.Resize(int(IMG_SIZE*1.15)),\n",
        "    transforms.CenterCrop(IMG_SIZE),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD)\n",
        "])\n",
        "\n",
        "def safe_open_image(path):\n",
        "    # Thử PIL trước\n",
        "    try:\n",
        "        img = Image.open(path).convert('RGB')\n",
        "        return img\n",
        "    except Exception:\n",
        "        pass\n",
        "    # Fallback OpenCV\n",
        "    img_cv = cv2.imread(path, cv2.IMREAD_COLOR)\n",
        "    if img_cv is None:\n",
        "        raise ValueError(f'Không thể đọc ảnh: {path}')\n",
        "    img_cv = cv2.cvtColor(img_cv, cv2.COLOR_BGR2RGB)\n",
        "    return Image.fromarray(img_cv)\n",
        "\n",
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, paths, labels, transform=None):\n",
        "        self.paths = paths\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "        # Placeholder image used when an image file cannot be opened\n",
        "        try:\n",
        "            from PIL import Image as _Image\n",
        "            self._placeholder = _Image.new('RGB', (IMG_SIZE, IMG_SIZE), (0, 0, 0))\n",
        "        except Exception:\n",
        "            self._placeholder = None\n",
        "    def __len__(self):\n",
        "        return len(self.paths)\n",
        "    def __getitem__(self, idx):\n",
        "        p = self.paths[idx]\n",
        "        y = self.labels[idx]\n",
        "        try:\n",
        "            img = safe_open_image(p)\n",
        "        except Exception as e:\n",
        "            # Nếu không thể mở ảnh, log và sử dụng ảnh placeholder để không làm crash DataLoader\n",
        "            print(f\"Warning: Không thể đọc ảnh {p}: {e}. Sử dụng ảnh placeholder.\")\n",
        "            if self._placeholder is not None:\n",
        "                img = self._placeholder.copy()\n",
        "            else:\n",
        "                # Cuối cùng nếu không có placeholder thì raise để người dùng biết\n",
        "                raise e\n",
        "        if self.transform:\n",
        "            try:\n",
        "                img = self.transform(img)\n",
        "            except Exception as e:\n",
        "                # Nếu transform thất bại trên ảnh (ví dụ kích thước bất thường), dùng placeholder tensor\n",
        "                print(f\"Warning: Transform thất bại cho {p}: {e}. Dùng ảnh placeholder đã chuẩn hoá.\")\n",
        "                if self._placeholder is not None:\n",
        "                    img = self.transform(self._placeholder.copy())\n",
        "                else:\n",
        "                    raise e\n",
        "        return img, y\n",
        "\n",
        "# Update: Load data from the processed_dataset directories\n",
        "output_data_dir = Path(OUTPUT + 'processed_dataset')\n",
        "train_dir = output_data_dir / 'train'\n",
        "val_dir = output_data_dir / 'val'\n",
        "test_dir = output_data_dir / 'test'\n",
        "\n",
        "# Function to list images and labels from a directory structure\n",
        "def list_images_from_dir(directory):\n",
        "    paths = []\n",
        "    labels = []\n",
        "    for cls_idx, cls_name in enumerate(CLASS_NAMES):\n",
        "        cls_dir = directory / cls_name\n",
        "        files = [str(p) for p in cls_dir.rglob('*') if p.is_file() and p.suffix.lower() in ALLOWED_EXTS]\n",
        "        paths.extend(files)\n",
        "        labels.extend([cls_idx] * len(files))\n",
        "    return paths, labels\n",
        "\n",
        "train_paths, train_labels = list_images_from_dir(train_dir)\n",
        "val_paths, val_labels = list_images_from_dir(val_dir)\n",
        "test_paths, test_labels = list_images_from_dir(test_dir)\n",
        "\n",
        "train_ds = ImageDataset(train_paths, train_labels, train_tfms)\n",
        "val_ds = ImageDataset(val_paths, val_labels, eval_tfms)\n",
        "test_ds = ImageDataset(test_paths, test_labels, eval_tfms)\n",
        "print('Số mẫu train/val/test:', len(train_ds), len(val_ds), len(test_ds))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "A85IeLuuhS-l",
      "metadata": {
        "id": "A85IeLuuhS-l"
      },
      "source": [
        "## 5) Xử lý mất cân bằng: WeightedRandomSampler (oversampling lớp nhỏ)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "TtNIj6YphS-m",
      "metadata": {
        "id": "TtNIj6YphS-m"
      },
      "outputs": [],
      "source": [
        "cnt = Counter(train_labels)\n",
        "print('Phân bố train:', {CLASS_NAMES[k]: v for k,v in cnt.items()})\n",
        "\n",
        "# Trọng số mẫu = 1 / tần suất lớp\n",
        "class_freq = np.array([cnt.get(i, 0) for i in range(NUM_CLASSES)], dtype=np.float64)\n",
        "class_freq[class_freq==0] = 1\n",
        "class_weight = 1.0 / class_freq\n",
        "sample_weights = np.array([class_weight[y] for y in train_labels], dtype=np.float64)\n",
        "sampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(sample_weights), replacement=True)\n",
        "print('Đã tạo WeightedRandomSampler (oversampling lớp ít).')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6g02sFerhS-n",
      "metadata": {
        "id": "6g02sFerhS-n"
      },
      "source": [
        "## 6) DataLoaders + MixUp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9aNt_5E4hS-n",
      "metadata": {
        "id": "9aNt_5E4hS-n"
      },
      "outputs": [],
      "source": [
        "\n",
        "mixup_fn = None\n",
        "if MIXUP:\n",
        "    mixup_fn = Mixup(mixup_alpha=MIXUP_ALPHA, cutmix_alpha=CUTMIX_ALPHA,\n",
        "                     prob=1.0, switch_prob=0.0, mode='batch',\n",
        "                     label_smoothing=LABEL_SMOOTHING, num_classes=NUM_CLASSES)\n",
        "    print(' MixUp đang bật')\n",
        "else:\n",
        "    print(' MixUp tắt')\n",
        "\n",
        "def collate_fn(batch):\n",
        "    imgs, labels = list(zip(*batch))\n",
        "    imgs = torch.stack(imgs, dim=0)\n",
        "    labels = torch.tensor(labels, dtype=torch.long)\n",
        "    if mixup_fn is not None:\n",
        "        imgs, labels = mixup_fn(imgs, labels)\n",
        "    return imgs, labels\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, sampler=sampler,\n",
        "                          num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY,\n",
        "                          drop_last=True, collate_fn=collate_fn)\n",
        "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)\n",
        "test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)\n",
        "len(train_loader), len(val_loader), len(test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "-SqYPPm0hS-o",
      "metadata": {
        "id": "-SqYPPm0hS-o"
      },
      "source": [
        "## 7) Khởi tạo ViT + optimizer, loss, scheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vrXZ1fWfhS-o",
      "metadata": {
        "id": "vrXZ1fWfhS-o"
      },
      "outputs": [],
      "source": [
        "use_local = local_model_dir.exists()\n",
        "try:\n",
        "    if use_local:\n",
        "        print(f\"Tìm thấy thư mục mô hình local: {local_model_dir}. Load từ local với num_labels={NUM_CLASSES}\\n\")\n",
        "        id2label = {i: name for i, name in enumerate(CLASS_NAMES)}\n",
        "        label2id = {name: i for i, name in enumerate(CLASS_NAMES)}\n",
        "        model = ViTForImageClassification.from_pretrained(\n",
        "            str(local_model_dir),\n",
        "            num_labels=NUM_CLASSES,\n",
        "            id2label=id2label,\n",
        "            label2id=label2id,\n",
        "            ignore_mismatched_sizes=True,\n",
        "            local_files_only=True,\n",
        "        )\n",
        "        if getattr(model.config, \"num_labels\", None) != NUM_CLASSES or (hasattr(model, \"classifier\") and getattr(model.classifier, \"out_features\", None) != NUM_CLASSES):\n",
        "            hidden = model.config.hidden_size\n",
        "            model.classifier = nn.Linear(hidden, NUM_CLASSES)\n",
        "            model.config.num_labels = NUM_CLASSES\n",
        "            model.config.id2label = id2label\n",
        "            model.config.label2id = label2id\n",
        "    else:\n",
        "        print(f\"Không tìm thấy model local, sẽ tải '{MODEL_NAME}' từ HuggingFace với num_labels={NUM_CLASSES}\")\n",
        "        model = ViTForImageClassification.from_pretrained(MODEL_NAME)\n",
        "\n",
        "    try:\n",
        "        model_config = model.config\n",
        "        if getattr(model_config, 'num_labels', None) != NUM_CLASSES:\n",
        "            print(f\"Đang điều chỉnh head từ {model_config.num_labels} sang {NUM_CLASSES} nhãn\")\n",
        "            hidden = model_config.hidden_size\n",
        "            model.classifier = torch.nn.Linear(hidden, NUM_CLASSES)\n",
        "            model.config.num_labels = NUM_CLASSES\n",
        "            model.config.id2label = {i: name for i, name in enumerate(CLASS_NAMES)}\n",
        "            model.config.label2id = {name: i for i, name in enumerate(CLASS_NAMES)}\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "except Exception as e:\n",
        "    print('Lỗi khởi tạo mô hình HF ViT hoặc tải trọng số:', e)\n",
        "    try:\n",
        "        if use_local:\n",
        "            cfg = ViTConfig.from_pretrained(str(local_model_dir), local_files_only=True)\n",
        "        else:\n",
        "            cfg = ViTConfig.from_pretrained(MODEL_NAME)\n",
        "    except Exception:\n",
        "        cfg = ViTConfig()\n",
        "    cfg.num_labels = NUM_CLASSES\n",
        "    model = ViTForImageClassification(cfg)\n",
        "    model.config.id2label = {i: name for i, name in enumerate(CLASS_NAMES)}\n",
        "    model.config.label2id = {name: i for i, name in enumerate(CLASS_NAMES)}\n",
        "\n",
        "num_ftrs = model.classifier.in_features\n",
        "model.classifier = nn.Linear(num_ftrs, NUM_CLASSES)\n",
        "\n",
        "model.to(DEVICE)\n",
        "print('Số tham số huấn luyện:', sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
        "\n",
        "if MIXUP:\n",
        "    criterion = SoftTargetCrossEntropy()\n",
        "else:\n",
        "    criterion = nn.CrossEntropyLoss(label_smoothing=LABEL_SMOOTHING)\n",
        "\n",
        "optimizer = optim.AdamW(model.parameters(), lr=BASE_LR, weight_decay=WEIGHT_DECAY)\n",
        "\n",
        "main_scheduler = CosineAnnealingLR(optimizer, T_max=max(1, EPOCHS - WARMUP_EPOCHS))\n",
        "if WARMUP_EPOCHS > 0:\n",
        "    warmup_scheduler = LinearLR(optimizer, start_factor=0.1, end_factor=1.0, total_iters=WARMUP_EPOCHS)\n",
        "    scheduler = SequentialLR(optimizer, schedulers=[warmup_scheduler, main_scheduler], milestones=[WARMUP_EPOCHS])\n",
        "else:\n",
        "    scheduler = main_scheduler\n",
        "\n",
        "scaler = torch.amp.GradScaler('cuda', enabled=torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "p9ssfUM2hS-p",
      "metadata": {
        "id": "p9ssfUM2hS-p"
      },
      "source": [
        "## 8) Vòng lặp huấn luyện + EarlyStopping + Checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "BEefjsr1hS-q",
      "metadata": {
        "id": "BEefjsr1hS-q"
      },
      "outputs": [],
      "source": [
        "def accuracy_from_logits(logits, targets):\n",
        "    if logits.ndim == 2 and targets.ndim == 2:\n",
        "        preds = logits.argmax(dim=1)\n",
        "        y = targets.argmax(dim=1)\n",
        "    else:\n",
        "        preds = logits.argmax(dim=1)\n",
        "        y = targets\n",
        "    return (preds == y).float().mean().item()\n",
        "\n",
        "def train_one_epoch(epoch):\n",
        "    model.train()\n",
        "    total_loss, total_acc, n_batches = 0.0, 0.0, 0\n",
        "    print(f\"\\nBắt đầu epoch {epoch}/{EPOCHS} lúc: {datetime.datetime.now()}\")\n",
        "\n",
        "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch}/{EPOCHS} [TRAIN]\", leave=False)\n",
        "    for imgs, labels in progress_bar:\n",
        "        imgs = imgs.to(DEVICE, non_blocking=True)\n",
        "        labels = labels.to(DEVICE)\n",
        "\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        with autocast('cuda', enabled=torch.cuda.is_available()):\n",
        "            outputs = model(imgs)\n",
        "            logits = outputs.logits if hasattr(outputs, 'logits') else outputs\n",
        "            loss = criterion(logits, labels)\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        acc = accuracy_from_logits(logits.detach(), labels.detach())\n",
        "        total_loss += loss.item()\n",
        "        total_acc += acc\n",
        "        n_batches += 1\n",
        "\n",
        "        progress_bar.set_postfix(loss=loss.item(), acc=acc)\n",
        "\n",
        "    return total_loss / max(1,n_batches), total_acc / max(1,n_batches)\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(loader):\n",
        "    model.eval()\n",
        "    total_loss, total_acc, n_batches = 0.0, 0.0, 0\n",
        "    eval_criterion = nn.CrossEntropyLoss(label_smoothing=LABEL_SMOOTHING)\n",
        "\n",
        "    progress_bar = tqdm(loader, desc=\"[EVAL]\", leave=False)\n",
        "    for imgs, labels in progress_bar:\n",
        "        imgs = imgs.to(DEVICE, non_blocking=True)\n",
        "        labels = labels.to(DEVICE)\n",
        "        with autocast('cuda', enabled=torch.cuda.is_available()):\n",
        "            outputs = model(imgs)\n",
        "            logits = outputs.logits if hasattr(outputs, 'logits') else outputs\n",
        "            loss = eval_criterion(logits, labels)\n",
        "        acc = accuracy_from_logits(logits, labels)\n",
        "        total_loss += loss.item()\n",
        "        total_acc += acc\n",
        "        n_batches += 1\n",
        "        progress_bar.set_postfix(loss=loss.item(), acc=acc)\n",
        "\n",
        "    return total_loss / max(1,n_batches), total_acc / max(1,n_batches)\n",
        "\n",
        "best_val_acc = -1.0\n",
        "patience, patience_count = EPOCHS / 2, 0\n",
        "history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
        "ckpt_dir = Path(OUTPUT + 'checkpoints')\n",
        "ckpt_dir.mkdir(parents=True, exist_ok=True)\n",
        "best_dir = ckpt_dir / 'model'\n",
        "\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "    t0 = time.time()\n",
        "    tr_loss, tr_acc = train_one_epoch(epoch)\n",
        "    val_loss, val_acc = evaluate(val_loader)\n",
        "    scheduler.step()\n",
        "    history['train_loss'].append(tr_loss)\n",
        "    history['train_acc'].append(tr_acc)\n",
        "    history['val_loss'].append(val_loss)\n",
        "    history['val_acc'].append(val_acc)\n",
        "    dt = time.time()-t0\n",
        "    print(f'Epoch {epoch}/{EPOCHS} | train_loss={tr_loss:.4f} acc={tr_acc:.4f} | val_loss={val_loss:.4f} acc={val_acc:.4f} | {dt:.1f}s')\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        patience_count = 0\n",
        "\n",
        "        model.config.id2label = {i: name for i, name in enumerate(CLASS_NAMES)}\n",
        "        model.config.label2id = {name: i for i, name in enumerate(CLASS_NAMES)}\n",
        "        model.save_pretrained(best_dir, safe_serialization=True)\n",
        "\n",
        "        with open(best_dir / 'metrics.json', 'w', encoding='utf-8') as f:\n",
        "            json.dump({'epoch': int(epoch), 'val_acc': float(val_acc)}, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "        print('********************************* Lưu best model:', best_dir)\n",
        "    else:\n",
        "        patience_count += 1\n",
        "        if patience_count >= patience:\n",
        "            print(f'Dừng huấn luyện sau {patience} epoch không cải thiện.')\n",
        "            break\n",
        "\n",
        "with open(ckpt_dir / 'training_history.pkl', 'wb') as f:\n",
        "    pickle.dump(history, f)\n",
        "print(' Huấn luyện xong. Lịch sử lưu vào training_history.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_IiZgkRJhS-r",
      "metadata": {
        "id": "_IiZgkRJhS-r"
      },
      "source": [
        "## 9) Biểu đồ Loss/Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6sdPPmz8hS-r",
      "metadata": {
        "id": "6sdPPmz8hS-r"
      },
      "outputs": [],
      "source": [
        "with open(ckpt_dir / 'training_history.pkl', 'rb') as f:\n",
        "    history = pickle.load(f)\n",
        "epochs_ran = range(1, len(history['train_loss'])+1)\n",
        "\n",
        "fig = plt.figure(figsize=(12,5))\n",
        "ax1 = fig.add_subplot(1,2,1)\n",
        "ax1.plot(epochs_ran, history['train_loss'], label='Train Loss')\n",
        "ax1.plot(epochs_ran, history['val_loss'],   label='Val Loss')\n",
        "ax1.set_title('Biểu đồ Loss'); ax1.set_xlabel('Epoch'); ax1.set_ylabel('Loss'); ax1.legend()\n",
        "\n",
        "ax2 = fig.add_subplot(1,2,2)\n",
        "ax2.plot(epochs_ran, history['train_acc'], label='Train Acc')\n",
        "ax2.plot(epochs_ran, history['val_acc'],   label='Val Acc')\n",
        "ax2.set_title('Biểu đồ Accuracy'); ax2.set_xlabel('Epoch'); ax2.set_ylabel('Accuracy'); ax2.legend()\n",
        "\n",
        "fig.tight_layout()\n",
        "out_plot = ckpt_dir / 'loss_accuracy_plot.png'\n",
        "fig.savefig(out_plot, bbox_inches='tight', dpi=200)\n",
        "print(f\"Biểu đồ Loss và Accuracy đã được lưu tại {out_plot}\")\n",
        "\n",
        "plt.show()\n",
        "plt.close(fig)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "swWcT9iYhS-s",
      "metadata": {
        "id": "swWcT9iYhS-s"
      },
      "source": [
        "## 10) Đánh giá trên Test + Báo cáo chi tiết"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "iuY3yBm5hS-s",
      "metadata": {
        "id": "iuY3yBm5hS-s"
      },
      "outputs": [],
      "source": [
        "best_dir = ckpt_dir / 'model'\n",
        "\n",
        "model = ViTForImageClassification.from_pretrained(best_dir)\n",
        "model.to(DEVICE)\n",
        "model.eval()\n",
        "\n",
        "@torch.no_grad()\n",
        "def predict_loader(loader):\n",
        "    y_true, y_pred = [], []\n",
        "    for imgs, labels in loader:\n",
        "        imgs = imgs.to(DEVICE)\n",
        "        outputs = model(imgs)\n",
        "        logits = outputs.logits if hasattr(outputs, 'logits') else outputs\n",
        "        preds = logits.argmax(dim=1).cpu().numpy().tolist()\n",
        "        y_pred += preds\n",
        "        y_true += labels.numpy().tolist()\n",
        "    return y_true, y_pred\n",
        "\n",
        "y_true, y_pred = predict_loader(test_loader)\n",
        "report = classification_report(y_true, y_pred, target_names=CLASS_NAMES, digits=4)\n",
        "print('Báo cáo phân loại (Test):')\n",
        "print(report)\n",
        "\n",
        "report_path = ckpt_dir / 'classification_report.txt'\n",
        "with open(report_path, 'w') as f:\n",
        "    f.write(report)\n",
        "print(f\"Báo cáo phân loại đã được lưu tại {report_path}\")\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "fig, ax = plt.subplots(figsize=(8,6))\n",
        "\n",
        "sns.heatmap(cm[:, ::-1], annot=True, fmt='d', cmap='Blues', xticklabels=CLASS_NAMES[::-1], yticklabels=CLASS_NAMES, ax=ax)\n",
        "ax.set_title('Ma trận nhầm lẫn (Test)'); ax.set_xlabel('Dự đoán'); ax.set_ylabel('Thực tế')\n",
        "fig.tight_layout()\n",
        "cm_path = ckpt_dir / 'confusion_matrix.png'\n",
        "fig.savefig(cm_path, bbox_inches='tight', dpi=200)\n",
        "print(f\"Ma trận nhầm lẫn đã được lưu tại {cm_path}\")\n",
        "plt.show()\n",
        "plt.close(fig)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "igf0Pi2ahS-t",
      "metadata": {
        "id": "igf0Pi2ahS-t"
      },
      "source": [
        "## 11) Test với những ảnh ngoài dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9d0e045b"
      },
      "source": [
        "if os.path.exists('/kaggle'):\n",
        "    TESTDIR = '/kaggle/input/test-images'\n",
        "    print(TESTDIR)\n",
        "elif 'google.colab' in sys.modules:\n",
        "    TESTDIR = '/content/drive/MyDrive/test_images/'\n",
        "    print(TESTDIR)\n",
        "\n",
        "if not TESTDIR.exists():\n",
        "    print(f\"Thư mục test ngoài dataset không tồn tại tại {TESTDIR}\")\n",
        "else:\n",
        "    all_files = [p for p in TESTDIR.rglob('*') if p.is_file() and p.suffix.lower() in ALLOWED_EXTS]\n",
        "\n",
        "    num_samples = len(all_files)\n",
        "\n",
        "    if num_samples > 0:\n",
        "        random_image_paths = random.sample(all_files, num_samples)\n",
        "\n",
        "        best_dir = ckpt_dir / 'model'\n",
        "        model = ViTForImageClassification.from_pretrained(best_dir)\n",
        "        model.to(DEVICE)\n",
        "        model.eval()\n",
        "\n",
        "        test_inference_tfms = transforms.Compose([\n",
        "            transforms.Resize(int(IMG_SIZE*1.15)),\n",
        "            transforms.CenterCrop(IMG_SIZE),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD)\n",
        "        ])\n",
        "        print(f\"\\nĐang dự đoán cho {num_samples} ảnh ngẫu nhiên từ {TESTDIR}:\")\n",
        "\n",
        "        fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
        "        axes = axes.flatten()\n",
        "\n",
        "        for i, img_path in enumerate(random_image_paths):\n",
        "            try:\n",
        "                img = safe_open_image(img_path)\n",
        "                img_tensor = test_inference_tfms(img).unsqueeze(0).to(DEVICE)\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    outputs = model(img_tensor)\n",
        "                    logits = outputs.logits if hasattr(outputs, 'logits') else outputs\n",
        "                    probabilities = torch.softmax(logits, dim=1)[0]\n",
        "                    predicted_class_idx = torch.argmax(probabilities).item()\n",
        "                    predicted_class_name = model.config.id2label[predicted_class_idx]\n",
        "                    confidence = probabilities[predicted_class_idx].item()\n",
        "\n",
        "                axes[i].imshow(img)\n",
        "                axes[i].set_title(f\"Dự đoán: {predicted_class_name}\\n({confidence:.2f})\", fontsize=10)\n",
        "                axes[i].axis('off')\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Không thể xử lý ảnh {img_path}: {e}\")\n",
        "                axes[i].set_title(f\"Lỗi xử lý ảnh\", fontsize=10)\n",
        "                axes[i].axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    else:\n",
        "        print(f\"Không tìm thấy ảnh nào để test trong thư mục {TESTDIR}.\")\n",
        "\n",
        "print(f\"Kết thúc quá trình lúc: {datetime.datetime.now()}\")"
      ],
      "id": "9d0e045b",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}